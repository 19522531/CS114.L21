{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train_issarcasm.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMKOY39Tz6lHLwionhxkctG",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/19522531/CS114.L21/blob/main/Colab/b%C3%A0i%20to%C3%A1n%20Sarcasm%20detection%20in%20news%20headline/Train_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULkatSc63mZj"
      },
      "source": [
        "#Bài toán phát hiện mỉa mai, châm biếm dựa trên tiêu đề bài báo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgB1JyGc3xzJ"
      },
      "source": [
        "## Xác định bối cảnh yêu cầu:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SvWhdpM3685"
      },
      "source": [
        "1. Xây dựng mô hình phân lớp nhị phân dự đoán một bài báo là châm biếm hay không.\n",
        "2. Bài toán:\n",
        "- Input: Là tiêu đề của bài báo\n",
        "- Output: Châm biếm hay không."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUGjDAgr4f-s"
      },
      "source": [
        "## Thêm các thư viện cần thiết\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3yX5ep15kTA"
      },
      "source": [
        "#đọc, khám phá và tiền xử lý dữ liệu\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "from nltk import pos_tag, word_tokenize\n",
        "\n",
        "# Khám phá dữ liệu:\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud,STOPWORDS\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.utils import shuffle # trộn lại dữ liệu\n",
        "\n",
        "#cân bằng lại dữ liệu\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.datasets import make_classification\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "from matplotlib import pyplot\n",
        "from numpy import where\n",
        "\n",
        "#model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow.keras.layers import Dropout\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from keras import layers\n",
        "import keras\n",
        "\n",
        "# Đánh giá mô hình\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDTZqvr9IjAP"
      },
      "source": [
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqEz1H1R6DGN"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqnWrB3j4Ypf"
      },
      "source": [
        "##Đọc dữ liệu đã  thu thập \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDvEcAw76cJi"
      },
      "source": [
        "def read_file_train(name):\n",
        "  if name == \"not_Satirical\":\n",
        "    ls = !ls \"/content/gdrive/MyDrive/CS114 - Máy học/Dataset - Sarcasm detection/Train/Not_Satirical\"\n",
        "    path = \"/content/gdrive/MyDrive/CS114 - Máy học/Dataset - Sarcasm detection/Train/Not_Satirical\"\n",
        "  else:\n",
        "    ls = !ls \"/content/gdrive/MyDrive/CS114 - Máy học/Dataset - Sarcasm detection/Train/Satirical\"\n",
        "    path = \"/content/gdrive/MyDrive/CS114 - Máy học/Dataset - Sarcasm detection/Train/Satirical\"\n",
        "  lst = ls[0].split()\n",
        "  lst_sentences = []\n",
        "  lst_labels = []\n",
        "  for i in lst:\n",
        "    path_ = path +\"/\" + str(i)\n",
        "    data = pd.read_csv(path_)\n",
        "    data = data.dropna()\n",
        "    lst_sentences += data['headline'].tolist()\n",
        "    lst_labels += data['is_sarcastic'].tolist()\n",
        "  return lst_sentences, lst_labels\n",
        "def read_file_test(name):\n",
        "  if name==\"not_Satirical\":\n",
        "    path = \"/content/gdrive/MyDrive/CS114 - Máy học/Dataset - Sarcasm detection/Test/Not_Satirical/thesuncouk_0.json\"\n",
        "    data = pd.read_json(path, lines= True)\n",
        "    lst_sentences = []\n",
        "    lst_labels = []\n",
        "    lst_sentences = data['headline'].tolist()\n",
        "    lst_labels = data['is_sarcastic'].tolist()\n",
        "    return lst_sentences, lst_labels\n",
        "  else:\n",
        "    path = \"/content/gdrive/MyDrive/CS114 - Máy học/Dataset - Sarcasm detection/Test/Satirical/Thebearverton_1.csv\"\n",
        "    data = pd.read_csv(path)\n",
        "    lst_sentences = []\n",
        "    lst_labels = []\n",
        "    lst_sentences = data['title'].tolist()\n",
        "    lst_labels = data['is_sarcastic'].tolist()\n",
        "    return lst_sentences, lst_labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MB4fjv6f7dNu"
      },
      "source": [
        "X1_train,y1_train = read_file_train(\"not_Satirical\")\n",
        "X2_train,y2_train = read_file_train(\"Satirical\")\n",
        "X1_test, y1_test = read_file_test(\"not_Satirical\")\n",
        "X2_test, y2_test =read_file_test(\"Satirical\")\n",
        "X_train = X1_train + X2_train\n",
        "y_train = y1_train + y2_train\n",
        "X_test = X1_test + X2_test\n",
        "y_test = y1_test + y2_test\n",
        "print(\"số lượng tiêu đề trong tập train:\" + str(len(X_train)))\n",
        "print(\"số lượng tiêu đề trong tập test: \" + str(len(X_test)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE4REHhH4kwo"
      },
      "source": [
        "#Tiền xử lý dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxlwtkfVBjEY"
      },
      "source": [
        "# Tokenization\n",
        "def replace(text):\n",
        "  text= text.replace(\"?\", \" ? \")\n",
        "  text= text.repace(\"!\", \" ! \")\n",
        "  text = text.replace(\"'\", \" ' \")\n",
        "  text = text.replace(\"@\", \" @ \")\n",
        "  text = text.repace (\"$\", \" $ \")\n",
        "  text = text.replace (\"%\", \" % \")\n",
        "  text = text.replace(\"&\", \" & \")\n",
        "  text = text.replace(\"*\", \" * \")\n",
        "  text = text.replace(\"(\", \" ( \")\n",
        "  text = text.replace(\")\", \" ) \")\n",
        "def tokenization_words(review):\n",
        "  return word_tokenize(review)\n",
        "\n",
        "# Join all token to the string\n",
        "def join_to_string(review):\n",
        "  return ' '.join(review)\n",
        "\n",
        "def  normalize(corpus):    \n",
        "    normalized_corpus = []    \n",
        "    for text in corpus:\n",
        "            text = tokenization_words(text)\n",
        "            text = join_to_string(text)            \n",
        "            normalized_corpus.append(text)\n",
        "        \n",
        "    return normalized_corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfrEhFzMGQUh"
      },
      "source": [
        "X_train_ = normalize(X_train)\n",
        "X_test_ = normalize(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-onGH_xD6esT"
      },
      "source": [
        "## Khám phá dữ liệu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTiipHUB6hBA"
      },
      "source": [
        "#số lượng nhãn 0 và 1 trogn tập train\n",
        "lst1 = [Counter(y_train)[0], Counter(y_train)[1]]\n",
        "plt.figure(figsize = (6, 6))\n",
        "marks = [\"Not_Satirical\", \"Satirical\"]\n",
        "plt.bar(marks, lst1, color = \"blue\")\n",
        "plt.title(\"Thống kê số lượng tiêu đề theo từng nhãn trong tập train\")\n",
        "plt.show()\n",
        "\n",
        "print(lst1, lst2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Be7E8bB7iWxQ"
      },
      "source": [
        "- tỷ lệ giữa nhãn 0 và 1 trong tập train rất chênh lệch theo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mTlsu0B_1ag"
      },
      "source": [
        "max = 0\n",
        "sum = 0\n",
        "for i in X_train:\n",
        "  z = i.split()\n",
        "  sum += len(z)\n",
        "  if (len(z)>max):\n",
        "    max = len(z)\n",
        "print(\"Câu có độ dài lớn nhất: \" + str(max))\n",
        "print(\"Độ dài trung bình của các tiêu đề: \" + str(sum/len(X_train)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVqiDiFpEAax"
      },
      "source": [
        "plt.figure(figsize = (20,20)) \n",
        "text = \" \".join(review for review in X_train)\n",
        "wc = WordCloud(max_words = 2000 , width = 1600 , height = 1600).generate(text)\n",
        "plt.imshow(wc , interpolation = 'bilinear')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1jHLyANQdkR"
      },
      "source": [
        "# Chuyển dữ liệu về vector đặc trưng"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZFwN5KgfVDi"
      },
      "source": [
        "vocab_size = 60000 \n",
        "embedding_dim = 6\n",
        "max_length = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "006h0jI0fbfk"
      },
      "source": [
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train_) #Tạo bộ từ vựng dựa trên tập train."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyK1KP6yfh63"
      },
      "source": [
        "train_sequences = tokenizer.texts_to_sequences(X_train_) #chuyển từ headline thành list các số nguyên dựa trên vị trí trong bộ từ vựng\n",
        "test_sequences = tokenizer.texts_to_sequences(X_test_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDXkUfN7cUNU"
      },
      "source": [
        "print(X_train_[1])\n",
        "train_sequences[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-AZQBqefk9L"
      },
      "source": [
        "padded_train_sequences = pad_sequences(train_sequences, maxlen = max_length, truncating= \"post\", padding = \"post\") #chuyển các vector thành các vector có cùng độ dài\n",
        "padded_test_sequences = pad_sequences(test_sequences, maxlen = max_length, truncating=\"post\", padding = \"post\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlZNW4sxWmB9"
      },
      "source": [
        "# trộn lại dữ liệu ngẫu nhiên\n",
        "X_train, y_train = shuffle(padded_train_sequences, y_train, random_state=0) \n",
        "X_test, y_test = shuffle(padded_test_sequences, y_test, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuIwgtoU_liW"
      },
      "source": [
        "##Huấn luyện mô hình\n",
        "###Feature Engineering với Word2Vec\n",
        "- Word2Vec = CBOW (continous bag of words) + Skip gram\n",
        "- Điểm chung: được build dựa trên mạng neuron 3 lớp: Input Layer, Hidden Layer, Output Layer.\n",
        "- Mục đích: Học các trọng số biểu diễn vector từ\n",
        "- CBOW: dự đoán xác suất của một từ được đưa ra theo ngữ cảnh\n",
        "- Skip gram: dự đoán ngữ cảnh của một từ đưa vào"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJOMFPmHfJ9B"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(layers.Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
        "model.add(layers.Conv1D(64, 3, activation='relu'))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dropout(0.3)) \n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-pye4W9ftAJ"
      },
      "source": [
        "history = model.fit(X_train, np.array(y_train), epochs=10)\n",
        "# lưu lại model\n",
        "!mkdir -p saved_model\n",
        "model.save('/content/gdrive/MyDrive/CS114 - Máy học/Dataset - Sarcasm detection/saved_model1/my_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQXQLgkwgDyU"
      },
      "source": [
        "#dự đoán tập test\n",
        "model  = tf.keras.models.load_model(\"/content/gdrive/MyDrive/CS114 - Máy học/Dataset - Sarcasm detection/saved_model1/my_model\")\n",
        "predict = model.predict(padded_test_sequences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJL_YUgkE2ht"
      },
      "source": [
        "lst = []\n",
        "for i in predict:\n",
        "  if (i<0.5):\n",
        "    lst.append(0)\n",
        "  else:\n",
        "    lst.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpBEhcxA4HlL"
      },
      "source": [
        "def CM_plot(M):\n",
        "    X = [i/np.sum(i) for i in M]\n",
        "    plt.figure(figsize = (10,10))\n",
        "    sns.heatmap(X,cmap= \"Blues\", linecolor = 'black' , linewidth = 1 , annot = True, fmt='' , xticklabels = ['Not_Satiricle','Is_Satirical'] , yticklabels = ['Not_Satirical','Is_Satirical'])\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp7lB8od3Wv3"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, lst))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yty7uz11INKD"
      },
      "source": [
        "CM_plot(confusion_matrix(y_test, lst))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5FSAiHfbBG3"
      },
      "source": [
        "##Nhận xét: \n",
        "- Khả năng dự đoán đúng một bài báo châm biếm và không châm biếm thấp có thể  do số lượng giữa các nhãn trong tập bị mất cân bằng.\n",
        "- Số lượng headline của nhãn 1 (bài báo châm biếm) thấp hơn rất nhiều so với số lượng headline nhãn 0 ( bài báo chính thống) tỷ lệ 1/5 rất chênh lệch\n",
        "# Đề xuất sử dụng kĩ thuật smote để cân bằng lại dữ liệu giữa các nhãn\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C2fJF9sQ_In"
      },
      "source": [
        "#Xử lý lại dữ liệu mất cân bằng\n",
        "- Sử dụng kĩ thuật Smote\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiiqHMdXWR3_"
      },
      "source": [
        "#lấy dữ liệu\n",
        "X1_train,y1_train = read_file_train(\"not_Satirical\")\n",
        "X2_train,y2_train = read_file_train(\"Satirical\")\n",
        "X1_test, y1_test = read_file_test(\"not_Satirical\")\n",
        "X2_test, y2_test =read_file_test(\"Satirical\")\n",
        "X_train = X1_train + X2_train\n",
        "y_train = y1_train + y2_train\n",
        "X_test = X1_test + X2_test\n",
        "y_test = y1_test + y2_test\n",
        "print(\"số lượng tiêu đề trong tập train:\" + str(len(X_train)))\n",
        "print(\"số lượng tiêu đề trong tập test: \" + str(len(X_test)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovAyv6VzWxOJ"
      },
      "source": [
        "#tiền xử lý dữ liệu\n",
        "X_train_ = normalize(X_train)\n",
        "X_test_ = normalize(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO9FKUHGWnUI"
      },
      "source": [
        "# trích xuất đặc trưng\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train_)\n",
        "train_sequences = tokenizer.texts_to_sequences(X_train_)\n",
        "test_sequences = tokenizer.texts_to_sequences(X_test_)\n",
        "padded_train_sequences = pad_sequences(train_sequences, maxlen = max_length, truncating= \"post\", padding = \"post\")\n",
        "padded_test_sequences = pad_sequences(test_sequences, maxlen = max_length, truncating=\"post\", padding = \"post\")\n",
        "# trộn lại dữ liệu ngẫu nhiên\n",
        "X_train, y_train = shuffle(padded_train_sequences, y_train, random_state=0)\n",
        "X_test, y_test = shuffle(padded_test_sequences, y_test, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liQiJv3waLrA"
      },
      "source": [
        "#Cân bằng lại dữ liệu\n",
        "counter = Counter(y_train)\n",
        "print(counter)\n",
        "# define pipeline\n",
        "over = SMOTE(sampling_strategy=0.5)\n",
        "under = RandomUnderSampler(sampling_strategy=1)\n",
        "steps = [('o', over), ('u', under)]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "# transform the dataset\n",
        "X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
        "# summarize the new class distribution\n",
        "counter = Counter(y_train)\n",
        "print(counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N54-k8MNHxcH"
      },
      "source": [
        "#số lượng nhãn 0 và 1 trogn tập train\n",
        "lst1 = [Counter(y_train)[0], Counter(y_train)[1]]\n",
        "plt.figure(figsize = (6, 6))\n",
        "marks = [\"Not_Satirical\", \"Satirical\"]\n",
        "plt.bar(marks, lst1, color = \"blue\")\n",
        "plt.title(\"Thống kê số lượng tiêu đề theo từng nhãn trong tập train\")\n",
        "plt.show()\n",
        "print(lst1, lst2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dM3gfG6sVKfJ"
      },
      "source": [
        "#train lại model\n",
        "history = model.fit(X_train, np.array(y_train), epochs=10)\n",
        "!mkdir -p saved_model\n",
        "model.save('/content/gdrive/MyDrive/CS114 - Máy học/Dataset - Sarcasm detection/saved_model2/my_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hq7EdZZrXN_j"
      },
      "source": [
        "# dự đoán trên bộ test\n",
        "model = tf.keras.models.load_model('/content/gdrive/MyDrive/CS114 - Máy học/Dataset - Sarcasm detection/saved_model2/my_model')\n",
        "predict = model.predict(padded_test_sequences)\n",
        "lst = []\n",
        "for i in predict:\n",
        "  if (i<0.5):\n",
        "    lst.append(0)\n",
        "  else:\n",
        "    lst.append(1)\n",
        "print(classification_report(y_test, lst))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gH6R5MaazSR"
      },
      "source": [
        "CM_plot(confusion_matrix(y_test, lst))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSE2UZ37bcwA"
      },
      "source": [
        "## Nhận xét:\n",
        "- Sau khi cân bằng lại số lượng dữ liệu giữa các nhãn thì kết quả không đạt kết quả tốt hơn so với mô hình khi dữ liệu bị chênh lệch ban đầu\n",
        "- Tỷ lệ dự đoán đúng với nhãn 0 thì thấp tuy nhiên đối với nhãn 1 thì tốt hơn.\n",
        "- Để cải thiện mô hình tốt hơn nhóm tiếp tục thử nghiệm cải thiện mô hình bằng cách bổ sung dữ cho tập train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_RKh9bIcmal"
      },
      "source": [
        "def read_file_train_bonus(flag):\n",
        "  if flag == 1:\n",
        "    path = \"/content/gdrive/MyDrive/CS114 - Máy học/Dataset - Sarcasm detection/Train/Bonus Not_Satirical/TheDailyBonet_1.csv\"\n",
        "    data =pd.read_csv(path)\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    for i in range(len(data['headline'])):\n",
        "      X_train.append(data['headline'][i])\n",
        "      y_train.append(data['is_sarcastic'][i])\n",
        "    return X_train, y_train\n",
        "  elif flag == 2:\n",
        "    path =\"/content/gdrive/MyDrive/CS114 - Máy học/Dataset - Sarcasm detection/Train/Bonus Not_Satirical/Sarcasm_1.json\"\n",
        "    data =pd.read_json(path)\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    for i in range(len(data['headline'])):\n",
        "      X_train.append(data['headline'][i])\n",
        "      y_train.append(data['is_sarcastic'][i])\n",
        "    return X_train, y_train\n",
        "  elif flag == 3:\n",
        "    path =  \"/content/gdrive/MyDrive/CS114 - Máy học/Dataset - Sarcasm detection/Train/Bonus Not_Satirical/Trusted_0.json\"\n",
        "    data = pd.read_json(path)\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    for i in range(len(data['headline'])):\n",
        "      try:        \n",
        "        y_train.append(int(data['is_sarcastic'][i]))\n",
        "        X_train.append(data['headline'][i])\n",
        "      except:\n",
        "        z = 0\n",
        "    return X_train, y_train\n",
        "  elif flag==4:\n",
        "    path = \"/content/gdrive/MyDrive/CS114 - Máy học/Dataset - Sarcasm detection/Train/Bonus Not_Satirical/rochdaleherald.co.uk_1.csv\"\n",
        "    data= pd.read_csv(path)\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    for i in range(len(data['headline'])):\n",
        "      try:        \n",
        "        y_train.append(int(data['is_sarcastic'][i]))\n",
        "        X_train.append(data['headline'][i])\n",
        "      except:\n",
        "        z = 0\n",
        "    return X_train, y_train\n",
        "  else:\n",
        "    path = \"/content/gdrive/MyDrive/CS114 - Máy học/Dataset - Sarcasm detection/Train/Bonus Not_Satirical/thedailymash.co.uk_1 (1).csv\"\n",
        "    data = pd.read_csv(path)\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    for i in range(len(data['headline'])):\n",
        "      try:        \n",
        "        y_train.append(int(data['is_sarcastic'][i]))\n",
        "        X_train.append(data['headline'][i])\n",
        "      except:\n",
        "        z = 0\n",
        "    return X_train, y_train\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poQIqRUocKc-"
      },
      "source": [
        "X1_train,y1_train = read_file_train(\"not_Satirical\")\n",
        "print(Counter(y1_train))\n",
        "X2_train,y2_train = read_file_train(\"Satirical\")\n",
        "print(Counter(y2_train))\n",
        "X3_train, y3_train = read_file_train_bonus(1)\n",
        "print(Counter(y3_train))\n",
        "X4_train, y4_train = read_file_train_bonus(2)\n",
        "print(Counter(y4_train))\n",
        "X5_train, y5_train = read_file_train_bonus(3)\n",
        "print(Counter(y5_train))\n",
        "X6_train, y6_train = read_file_train_bonus(4)\n",
        "print(Counter(y6_train))\n",
        "X7_train, y7_train = read_file_train_bonus(5)\n",
        "print(Counter(y7_train))\n",
        "\n",
        "X1_test, y1_test = read_file_test(\"not_Satirical\")\n",
        "X2_test, y2_test =read_file_test(\"Satirical\")\n",
        "\n",
        "X_train = X1_train[:32000] + X2_train + X3_train+ X4_train+ X5_train + X6_train + X7_train\n",
        "y_train = y1_train[:32000] + y2_train + y3_train+ y4_train + y5_train + y6_train + y7_train\n",
        "X_test = X1_test + X2_test\n",
        "y_test = y1_test + y2_test\n",
        "print(\"số lượng tiêu đề trong tập train:\" + str(len(X_train)))\n",
        "print(\"số lượng tiêu đề trong tập test: \" + str(len(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4If40mCeeA-"
      },
      "source": [
        "#số lượng nhãn 0 và 1 trogn tập train và tập test\n",
        "lst1 = [Counter(y_train)[0], Counter(y_train)[1]]\n",
        "lst2 = [Counter(y_test)[0], Counter(y_test)[1]]\n",
        "print(Counter(y_train))\n",
        "plt.figure(figsize = (6, 6))\n",
        "marks = [\"Not_Satirical\", \"Satirical\"]\n",
        "plt.bar(marks, lst1, color = \"blue\")\n",
        "plt.title(\"Thống kê số lượng tiêu đề theo từng nhãn trong tập train\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2CUbU7ih4EK"
      },
      "source": [
        "#Tiền xử lý dữ liệu\n",
        "X_train_ = normalize(X_train)\n",
        "X_test_ = normalize(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMewnm9sgdqf"
      },
      "source": [
        "# trích xuất đặc trưng\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "train_sequences = tokenizer.texts_to_sequences(X_train_)\n",
        "test_sequences = tokenizer.texts_to_sequences(X_test_)\n",
        "padded_train_sequences = pad_sequences(train_sequences, maxlen = max_length, truncating= \"post\", padding = \"post\")\n",
        "padded_test_sequences = pad_sequences(test_sequences, maxlen = max_length, truncating=\"post\", padding = \"post\")\n",
        "# trộn lại dữ liệu ngẫu nhiên\n",
        "X_train, y_train = shuffle(padded_train_sequences, y_train, random_state=0)\n",
        "X_test, y_test = shuffle(padded_test_sequences, y_test, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4gcnheCAPn7"
      },
      "source": [
        "print(len(X_train))\n",
        "print(len(y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3oqu5YHhi91"
      },
      "source": [
        "#train lại model\n",
        "history = model.fit(X_train, np.array(y_train), epochs=10)\n",
        "#lưu lại model\n",
        "!mkdir -p saved_model\n",
        "model.save('/content/gdrive/MyDrive/CS114 - Máy học/Dataset - Sarcasm detection/saved_model3/my_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESEYk1kcW-gM"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "model = tf.keras.models.load_model(\"/content/gdrive/MyDrive/CS114 - Máy học/Dataset - Sarcasm detection/saved_model3/my_model\")\n",
        "predict = model.predict(X_train)\n",
        "lst = []\n",
        "for i in predict:\n",
        "  if (i<0.5):\n",
        "    lst.append(0)\n",
        "  else:\n",
        "    lst.append(1)\n",
        "print(classification_report(y_train, lst))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp6hVWhmiXOS"
      },
      "source": [
        "# dự đoán trên bộ test\n",
        "from sklearn.metrics import classification_report\n",
        "predict = model.predict(X_test)\n",
        "lst = []\n",
        "for i in predict:\n",
        "  if (i<0.5):\n",
        "    lst.append(0)\n",
        "  else:\n",
        "    lst.append(1)\n",
        "print(classification_report(y_test, lst))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvK8S1y6WJdZ"
      },
      "source": [
        "CM_plot(confusion_matrix(y_test, lst))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E39MCSy-VAxP"
      },
      "source": [
        "##Nhận xét:\n",
        "- Sau khi bổ sung thêm dữ liệu train thì kết quả đã được cải thiện.\n",
        "- Khả năng dự đoán đúng nhãn 0 và 1 đều trên 70% \n",
        "- \n",
        "\n",
        "## Nguồn tham khảo:\n",
        "- https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer\n",
        "- https://colab.research.google.com/github/hieubkset/Colab-Notebooks/blob/master/save_and_load.ipynb#scrollTo=NstL6zk_Ezg0\n",
        "- https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/\n",
        "- https://forum.machinelearningcoban.com/t/hoc-bieu-dien-ngon-ngu-cho-may-tinh/299\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW_YYB4CbBaP"
      },
      "source": [
        "## sử dụng phương pháp rút trích đặc trưng TF-IDF\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eZ1cWe8bVhf"
      },
      "source": [
        "X1_train,y1_train = read_file_train(\"not_Satirical\")\n",
        "print(Counter(y1_train))\n",
        "X2_train,y2_train = read_file_train(\"Satirical\")\n",
        "print(Counter(y2_train))\n",
        "X3_train, y3_train = read_file_train_bonus(1)\n",
        "print(Counter(y3_train))\n",
        "X4_train, y4_train = read_file_train_bonus(2)\n",
        "print(Counter(y4_train))\n",
        "X5_train, y5_train = read_file_train_bonus(3)\n",
        "print(Counter(y5_train))\n",
        "X6_train, y6_train = read_file_train_bonus(4)\n",
        "print(Counter(y6_train))\n",
        "X7_train, y7_train = read_file_train_bonus(5)\n",
        "print(Counter(y7_train))\n",
        "\n",
        "X1_test, y1_test = read_file_test(\"not_Satirical\")\n",
        "X2_test, y2_test =read_file_test(\"Satirical\")\n",
        "\n",
        "X_train = X1_train[:32000] + X2_train + X3_train+ X4_train+ X5_train + X6_train + X7_train\n",
        "y_train = y1_train[:32000] + y2_train + y3_train+ y4_train + y5_train + y6_train + y7_train\n",
        "X_test = X1_test + X2_test\n",
        "y_test = y1_test + y2_test\n",
        "print(\"số lượng tiêu đề trong tập train:\" + str(len(X_train)))\n",
        "print(\"số lượng tiêu đề trong tập test: \" + str(len(X_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dPtdhcLbYwR"
      },
      "source": [
        "#Tiền xử lý dữ liệu\n",
        "X_train_ = normalize(X_train)\n",
        "X_test_ = normalize(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEi3EPKucaIC"
      },
      "source": [
        "#trích xuất đặc trưng bằng phương pháp TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(X_train)\n",
        "print(vectorizer.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1izqPflcr2m"
      },
      "source": [
        "X_train = vectorizer.transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak18cGB4ctkq"
      },
      "source": [
        "from sklearn.svm import LinearSVC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EU1V1rtdUL2"
      },
      "source": [
        "clf = LinearSVC(C = 1, tol = 5e-5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SycunYRdaB_"
      },
      "source": [
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffTrvSQYdcKN"
      },
      "source": [
        "predict = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FkqbmBLdfG-"
      },
      "source": [
        "print(classification_report(y_test, lst))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PR8p7lerdoAa"
      },
      "source": [
        "## Nhận xét: \n",
        "- Sau khi thử nghiệm kết hợp giữa phương pháp trích xuất đặc trưng TF-IDF và mô hình máy học SVM thì cho kết quả thấp hơn so với phương pháp trích xuất đặc trưng Wordembedding và mô hình CNN."
      ]
    }
  ]
}